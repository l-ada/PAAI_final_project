{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7T_kCmpZuW3r"
      },
      "outputs": [],
      "source": [
        "import torch as tch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from toolbox import disp, disp_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "r0FoUaWUuW3v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xzM7Fq8cuW3v"
      },
      "outputs": [],
      "source": [
        "# device = 'cpu'\n",
        "# device = 'cuda'\n",
        "# batch_size=\n",
        "device = tch.device(\"cuda\" if tch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tZgbAWqjuW3w"
      },
      "outputs": [],
      "source": [
        "# input will be array in range[-1,1]\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "# should I augment the data?\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# Restricting to only ones.\n",
        "label_mask = train_dataset.targets == 1\n",
        "train_dataset.data = train_dataset.data[label_mask]\n",
        "train_dataset.targets = train_dataset.targets[label_mask]\n",
        "\n",
        "# subset_size = 500  # Choose the desired subset size max size is 50000\n",
        "# train_subset = tch.utils.data.Subset(train_dataset, range(subset_size))\n",
        "# test_subset = tch.utils.data.Subset(test_dataset, range(subset_size))\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = tch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = tch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "dhz0uB91uW3x"
      },
      "outputs": [],
      "source": [
        "n_directions = 6\n",
        "T = 1000\n",
        "beta_1 = 10**-4\n",
        "beta_T = 10**-2\n",
        "beta_1_tensor = tch.tensor(beta_1).to(device)\n",
        "height = 28\n",
        "width = 28\n",
        "# list containing \\bar{alpha_t}\n",
        "betas = tch.linspace(beta_1, beta_T, T, device=device)  # Linear schedule\n",
        "alphas = 1 - betas\n",
        "alphas_cumprod = tch.cumprod(alphas, dim=0)  # Cumulative product of alphas\n",
        "diffusion_scheduler = alphas_cumprod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vc_bHWU5uW3x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kw4k7lf9uW3y"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense1 = nn.Linear(784, 784)\n",
        "        self.reshape1 = nn.Unflatten(1, (1, 28, 28))\n",
        "        self.dense2 = nn.Linear(784, 7 * 7 * 64)\n",
        "        self.reshape2 = nn.Unflatten(1, (64, 7, 7))\n",
        "        self.conv_transpose1 = nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1)\n",
        "        self.conv_transpose2 = nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1)\n",
        "        self.conv_transpose3 = nn.ConvTranspose2d(32, 1, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        combined = x + t\n",
        "        x = self.flatten(combined)\n",
        "        x = self.dense1(x)\n",
        "        x1 = self.reshape1(x)\n",
        "\n",
        "        x = self.relu(self.dense2(x))\n",
        "        x = self.reshape2(x)\n",
        "        x = self.relu(self.conv_transpose1(x))\n",
        "        x = self.relu(self.conv_transpose2(x))\n",
        "        x = self.conv_transpose3(x)\n",
        "\n",
        "        output = x + x1\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8QGrM6-uW3y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJqQTpJ5uW30",
        "outputId": "592b9d7c-6996-479d-ef45-d7356a4bfae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modifiedUnet has 3,132,881 parameters.\n"
          ]
        }
      ],
      "source": [
        "# modifiedUnet = modifiedUnet(\n",
        "#     in_channels=1,\n",
        "#     out_channels=1,\n",
        "#     time_embedding_dimension=32,\n",
        "#     direction_embedding_dimension=32,\n",
        "#     n_classes=10).to(device)\n",
        "# #weights, loss function, optimizer\n",
        "modifiedUnet = Network()\n",
        "\n",
        "# Instantiate the model\n",
        "# optimizer and scheduler\n",
        "optimizer = tch.optim.AdamW(modifiedUnet.parameters(), lr=1e-3,\n",
        "                            weight_decay=1e-4)\n",
        "scheduler = tch.optim.lr_scheduler.StepLR(optimizer, step_size=10000,\n",
        "                                          gamma=0.2)\n",
        "loss_func = tch.nn.MSELoss(reduction='mean')\n",
        "\n",
        "\n",
        "total_params = sum(p.numel() for p in modifiedUnet.parameters())\n",
        "\n",
        "print(f\"modifiedUnet has {total_params:,} parameters.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vjMlJ8M_uW31"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def estimate_remaining_time(start_time, current_epoch, total_epochs):\n",
        "    \"\"\"Estimates the remaining training time.\n",
        "\n",
        "    Args:\n",
        "        start_time: The start time of the training process.\n",
        "        current_epoch: The current epoch number.\n",
        "        total_epochs: The total number of epochs.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    elapsed_time = time.time() - start_time\n",
        "    time_per_epoch = elapsed_time / (current_epoch + 1)\n",
        "    remaining_time = time_per_epoch * (total_epochs - current_epoch - 1)\n",
        "    remaining_hours = int(remaining_time // 3600)\n",
        "    remaining_minutes = int((remaining_time % 3600) // 60)\n",
        "    remaining_seconds = int(remaining_time % 60)\n",
        "    print(f\"Estimated remaining time: {remaining_hours:02d}:{remaining_minutes:02d}:{remaining_seconds:02d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uoRv0SxLuW33"
      },
      "outputs": [],
      "source": [
        "def normalize_data(images):\n",
        "    # for each image take a maximu of absolute values. Look at channels, height and width\n",
        "    # thus each image gets scaled individually\n",
        "    max_vals = tch.amax(tch.abs(images), dim=(1, 2, 3), keepdim=True)\n",
        "    # images are between [-1,1]\n",
        "    images = images/max_vals\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "JM96HdzDuW33",
        "outputId": "2ec0d2a8-288e-4a9a-cf8c-7d8a620e97fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 -- Total loss: 520519.47044\n",
            "Estimated remaining time: 00:28:14\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-cd8ee293ecf2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training\n",
        "running_loss = 0.0\n",
        "epoch_loss_ = 0.0\n",
        "epoch_loss = 0.0\n",
        "n_epoch = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epoch):\n",
        "    i = 0\n",
        "    for data in train_loader:\n",
        "        ###### COMPLETER ICI ######\n",
        "\n",
        "        loss_val = 0 # requis aux lignes suivantes\n",
        "        images,labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        current_batch_size = images.shape[0]\n",
        "        timesteps = tch.randint(1, T, size=(current_batch_size,), device=device)  # Move timesteps to the device\n",
        "        # generating a batch of random noise\n",
        "        timesteps = timesteps.view(-1, 1, 1, 1).to(device)\n",
        "        noise = tch.randn(current_batch_size, 1, height, width, device=device)\n",
        "        # alpha_bar = diffusion_scheduler[timesteps].view(-1,1,1,1).to(device)\n",
        "        # noised_image = tch.sqrt(alpha_bar)*images+tch.sqrt(1-alpha_bar)*noise\n",
        "        # predicted_noise = modifiedUnet(noised_image,labels, timesteps)\n",
        "        noised_image = images+timesteps*noise\n",
        "        noised_image = normalize_data(noised_image)\n",
        "        predicted_noise = modifiedUnet(noised_image, timesteps)\n",
        "        loss_val = loss_func(noise, predicted_noise)\n",
        "        loss_image = loss_func(images,noised_image-predicted_noise )\n",
        "        ## Gradient calculation\n",
        "        loss = loss_val+loss_image\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #####\n",
        "\n",
        "        running_loss += loss_val.item()\n",
        "        epoch_loss += loss_val.item()\n",
        "    print(f\"epoch= {epoch}\", end=\"\\r\", flush=True)\n",
        "    if epoch % 2 == 0:    # every 100 epoch...\n",
        "        disp_loss(epoch_loss, epoch)\n",
        "        estimate_remaining_time(start_time, epoch, n_epoch)\n",
        "\n",
        "    i = i+1\n",
        "    epoch_loss = 0.0\n",
        "    scheduler.step()\n",
        "print(\"Finished training\")\n",
        "#save the model weights after training\n",
        "tch.save(modifiedUnet.state_dict(), 'model_weights.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBLw3JUUuW34"
      },
      "outputs": [],
      "source": [
        "# loading model from weights\n",
        "state_dict = tch.load(\"model_weights.pth\")\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "modifiedUnet.load_state_dict(state_dict)\n",
        "\n",
        "modifiedUnet = modifiedUnet.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "modifiedUnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYZgfD0quW35"
      },
      "outputs": [],
      "source": [
        "\n",
        "# how to generate image from noise\n",
        "# algorith from DDPM paper\n",
        "# def generate_image(n_images, labels, noise_predictor, device=device):\n",
        "#     labels = tch.tensor(labels).to(device)\n",
        "#     images = tch.randn(n_images, 1, height, width).to(device)\n",
        "#     images = normalize_data(images)\n",
        "#     i = T - 1\n",
        "#     while i >= 0:\n",
        "#         times = tch.tensor([i] * n_images).to(device)\n",
        "#         alpha_bar = diffusion_scheduler[i].to(device)\n",
        "#         if i > 0:\n",
        "#             noise = tch.randn(n_images, 1, height, width).to(device)\n",
        "#         else:\n",
        "#             noise = images * 0\n",
        "#         images = (1 / tch.sqrt(alphas[i])) * (images - (1 - alphas[i]) / tch.sqrt(1 - diffusion_scheduler[i]) * noise_predictor(images, labels, times)) + tch.sqrt(betas[i]) * noise\n",
        "#         images = normalize_data(images)\n",
        "#         i = i - 1  # Decrement i for the next iteration\n",
        "#     return images.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def generate_image(n_images, labels, noise_predictor, device=device):\n",
        "    labels = tch.tensor(labels).to(device)\n",
        "    images = tch.randn(n_images, 1, height, width).to(device)\n",
        "    images = normalize_data(images)\n",
        "    times = tch.tensor([T] * n_images).to(device)\n",
        "    images = images-noise_predictor(images, times)\n",
        "    return images.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R41p1b-WuW35"
      },
      "outputs": [],
      "source": [
        "images = generate_image(n_images=6, labels=[1,2,3,4,5,6], noise_predictor=modifiedUnet).squeeze(1)\n",
        "disp(images, shape = (1,6), scale=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}