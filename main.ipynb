{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from toolbox import disp, disp_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "# device = 'cuda'\n",
    "# batch_size=\n",
    "device = tch.device(\"cuda\" if tch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input will be array in range[-1,1] \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "# should I augment the data?\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Restricting to only ones.\n",
    "# label_mask = train_dataset.targets == 1\n",
    "# train_dataset.data = train_dataset.data[label_mask]\n",
    "# train_dataset.targets = train_dataset.targets[label_mask]\n",
    "\n",
    "subset_size = 512  # Choose the desired subset size max size is 50000\n",
    "train_subset = tch.utils.data.Subset(train_dataset, range(subset_size))\n",
    "test_subset = tch.utils.data.Subset(test_dataset, range(subset_size))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = tch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = tch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = 500\n",
    "beta_1 = 10**-4\n",
    "beta_T = 10**-2\n",
    "beta_1_tensor = tch.tensor(beta_1).to(device)\n",
    "height = 28\n",
    "width = 28\n",
    "# list containing \\bar{alpha_t}\n",
    "betas = tch.linspace(beta_1, beta_T, T, device=device)  # Linear schedule\n",
    "alphas = 1 - betas\n",
    "alphas_cumprod = tch.cumprod(alphas, dim=0)  # Cumulative product of alphas\n",
    "diffusion_scheduler = alphas_cumprod\n",
    "print(\"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #architecture from https://github.com/TeaPearce/Conditional_Diffusion_MNIST\n",
    "# class ResidualConvBlock(nn.Module):\n",
    "#     def __init__(\n",
    "#         self, in_channels: int, out_channels: int, is_res: bool = False\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "#         '''\n",
    "#         standard ResNet style convolutional block\n",
    "#         '''\n",
    "#         self.same_channels = in_channels==out_channels\n",
    "#         # do we add skip connections?\n",
    "#         self.is_res = is_res\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.GELU(),\n",
    "#         )\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.GELU(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x: tch.Tensor) -> tch.Tensor:\n",
    "#         if self.is_res:\n",
    "#             x1 = self.conv1(x)\n",
    "#             x2 = self.conv2(x1)\n",
    "#             # what's this\n",
    "#             # this adds on correct residual in case channels have increased\n",
    "#             if self.same_channels:\n",
    "#                 out = x + x2\n",
    "#             else:\n",
    "#                 out = x1 + x2 \n",
    "#             #why divide by 1.414\n",
    "#             return out / 1.414\n",
    "#         else:\n",
    "#             x1 = self.conv1(x)\n",
    "#             x2 = self.conv2(x1)\n",
    "#             return x2\n",
    "\n",
    "# class UnetDown(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(UnetDown, self).__init__()\n",
    "#         '''\n",
    "#         process and downscale the image feature maps\n",
    "#         '''\n",
    "#         # ResNet Block and MaxPool (reduce number of pixels by 4)\n",
    "#         layers = [ResidualConvBlock(in_channels, out_channels), nn.MaxPool2d(2)]\n",
    "#         self.model = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "# class UnetUp(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(UnetUp, self).__init__()\n",
    "#         '''\n",
    "#         process and upscale the image feature maps\n",
    "#         '''\n",
    "#         # why the channels twice?\n",
    "#         layers = [\n",
    "#             nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
    "#             ResidualConvBlock(out_channels, out_channels),\n",
    "#             ResidualConvBlock(out_channels, out_channels),\n",
    "#         ]\n",
    "#         self.model = nn.Sequential(*layers)\n",
    "#     # TODO Explain this\n",
    "#     def forward(self, x, skip):\n",
    "#         x = tch.cat((x, skip), 1)\n",
    "#         x = self.model(x)\n",
    "#         return x\n",
    "# # Embedding time or direction. \n",
    "# # Not positional embedding, \n",
    "# class EmbedFC(nn.Module):\n",
    "#     def __init__(self, input_dim, emb_dim):\n",
    "#         super(EmbedFC, self).__init__()\n",
    "#         '''\n",
    "#         generic one layer FC NN for embedding things  \n",
    "#         '''\n",
    "#         self.input_dim = input_dim\n",
    "#         layers = [\n",
    "#             nn.Linear(input_dim, emb_dim),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(emb_dim, emb_dim),\n",
    "#         ]\n",
    "#         self.model = nn.Sequential(*layers)\n",
    "\n",
    "# # TODO Explain\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, self.input_dim)\n",
    "#         return self.model(x)\n",
    "    \n",
    "\n",
    "\n",
    "# class ContextUnet(nn.Module):\n",
    "#     def __init__(self, in_channels, n_feat = 256, n_classes=10):\n",
    "#         super(ContextUnet, self).__init__()\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.n_feat = n_feat\n",
    "#         self.n_classes = n_classes\n",
    "\n",
    "#         self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n",
    "\n",
    "#         self.down1 = UnetDown(n_feat, n_feat)\n",
    "#         self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
    "\n",
    "#         self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())\n",
    "#         # why twe embeddings?\n",
    "#         self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "#         self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
    "#         self.contextembed1 = EmbedFC(n_classes, 2*n_feat)\n",
    "#         self.contextembed2 = EmbedFC(n_classes, 1*n_feat)\n",
    "        \n",
    "\n",
    "#         # TODO Explain up0\n",
    "#         self.up0 = nn.Sequential(\n",
    "#             # nn.ConvTranspose2d(6 * n_feat, 2 * n_feat, 7, 7), # when concat temb and cemb end up w 6*n_feat\n",
    "#             nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 7, 7), # otherwise just have 2*n_feat\n",
    "#             nn.GroupNorm(8, 2 * n_feat),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.up1 = UnetUp(4 * n_feat, n_feat)\n",
    "#         self.up2 = UnetUp(2 * n_feat, n_feat)\n",
    "#         self.out = nn.Sequential(\n",
    "#             nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1),\n",
    "#             nn.GroupNorm(8, n_feat),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(n_feat, self.in_channels, 3, 1, 1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, c, t, context_mask):\n",
    "#         # x is (noisy) image, c is context label, t is timestep, \n",
    "#         # context_mask says which samples to block the context on\n",
    "\n",
    "#         x = self.init_conv(x)\n",
    "#         down1 = self.down1(x)\n",
    "#         down2 = self.down2(down1)\n",
    "#         hiddenvec = self.to_vec(down2)\n",
    "\n",
    "#         # convert context to one hot embedding\n",
    "#         c = nn.functional.one_hot(c, num_classes=self.n_classes).type(tch.float)\n",
    "        \n",
    "#         # mask out context if context_mask == 1\n",
    "#         context_mask = context_mask[:, None]\n",
    "#         context_mask = context_mask.repeat(1,self.n_classes)\n",
    "#         context_mask = (-1*(1-context_mask)) # need to flip 0 <-> 1\n",
    "#         c = c * context_mask\n",
    "        \n",
    "#         # embed context, time step\n",
    "#         cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)\n",
    "#         temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n",
    "#         cemb2 = self.contextembed2(c).view(-1, self.n_feat, 1, 1)\n",
    "#         temb2 = self.timeembed2(t).view(-1, self.n_feat, 1, 1)\n",
    "\n",
    "#         # could concatenate the context embedding here instead of adaGN\n",
    "#         # hiddenvec = torch.cat((hiddenvec, temb1, cemb1), 1)\n",
    "\n",
    "#         up1 = self.up0(hiddenvec)\n",
    "#         # up2 = self.up1(up1, down2) # if want to avoid add and multiply embeddings\n",
    "#         up2 = self.up1(cemb1*up1+ temb1, down2)  # add and multiply embeddings\n",
    "#         up3 = self.up2(cemb2*up2+ temb2, down1)\n",
    "#         out = self.out(tch.cat((up3, x), 1))\n",
    "#         return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #architecture from https://github.com/TeaPearce/Conditional_Diffusion_MNIST\n",
    "\n",
    "class ResConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, skip_connection = False):\n",
    "        super().__init__()\n",
    "        self.same_channels = (in_channels==out_channels)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.skip_connection = skip_connection\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            # expects input of size (N,out_channels, H, W)\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            # Gaussian Linear Unit\n",
    "            nn.GELU(),\n",
    "            # Maybe use SiLu from the paper\n",
    "            # nn.SiLU()\n",
    "        )\n",
    "# Why two convolutional layers?\n",
    "# I'll try also without second layer\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            # expects input of size (N,out_channels, H, W)\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            # Gaussian Linear Unit\n",
    "            nn.GELU(),\n",
    "            # Maybe use SiLu from the paper\n",
    "            # nn.SiLU()\n",
    "    )\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        if self.skip_connection:\n",
    "            if self.same_channels:\n",
    "                out = x+x2\n",
    "            else:\n",
    "                out = x1+x2\n",
    "                # divide by sqrt(2) to normalize variance\n",
    "                # it's just easier to divide by 1.414 ~ sqrt(2)s\n",
    "            return out/1.414\n",
    "        else:\n",
    "            return x2\n",
    "        \n",
    "    # # Case for ResBLOCK having only 1 convolution\n",
    "    # def forward(self, x):\n",
    "    #     x1 = self.conv1(x)\n",
    "    #     return x1\n",
    "        \n",
    "# downsampling layer\n",
    "# reduces size of image by 2 in each dimension\n",
    "class UnetDown(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ResConvBlock(in_channels,out_channels),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "# Upsample the image.\n",
    "# Why Res block twice though?\n",
    "class UnetUp(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            ResConvBlock(out_channels, out_channels),\n",
    "            ResConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "    def forward(self,x, skip):\n",
    "        # add a skip connection as a separate channel.\n",
    "        # This doubles the number of channels, so UnetUp will double the number of channels\n",
    "        x = tch.cat((x,skip), dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "## layer for embedding time or context\n",
    "#  nothing complicated like positional embedding\n",
    "class EmbedFC(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "        )\n",
    "# input_dim is either n_classes(context) or 1(time)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "\n",
    "class ContextUnet(nn.Module):\n",
    "    # the main architecture. \n",
    "    def __init__(self,in_channels, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    " \n",
    "        self.in_channels = in_channels\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # num_groups for the sole GroupNorm Layer\n",
    "        # Was 8 in original repo\n",
    "        # So number of channels must be a multiple of 8\n",
    "        num_groups = 8\n",
    "        self.init = ResConvBlock(in_channels, num_features, skip_connection=True)\n",
    "        self.down1 = UnetDown(num_features,num_features)\n",
    "        self.down2 = UnetDown(num_features, 2*num_features)\n",
    "        # This takes 7x7 image and makes it into a vector (1x1) image\n",
    "        self.to_vec = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=7),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        # \n",
    "        self.up0 = nn.Sequential(\n",
    "        # take 1x1 image and upscale to 7x7\n",
    "        nn.ConvTranspose2d(2 * num_features, 2 * num_features, kernel_size=7, stride=7), # otherwise just have 2*num_features\n",
    "        nn.GroupNorm(num_groups, 2 * num_features),\n",
    "        # originally was RELu\n",
    "        nn.GELU(),\n",
    "        )\n",
    "        # This will add the embedding to input of up1 layer\n",
    "        self.embedtime1 = EmbedFC(1, 2*num_features)\n",
    "        self.embedcontext1 = EmbedFC(num_classes, 2*num_features)\n",
    "        # Because of skip connection we have to double number of features\n",
    "        self.up1 = UnetUp(4*num_features, num_features)\n",
    "\n",
    "        self.embedtime2 = EmbedFC(1, num_features)\n",
    "        self.embedcontext2 = EmbedFC(num_classes, num_features)\n",
    "        # Again skip connections\n",
    "        self.up2 = UnetUp(2*num_features, num_features)\n",
    "        \n",
    "        # skip connections again\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * num_features, num_features, kernel_size=3, stride=1,padding=1),\n",
    "            nn.GroupNorm(num_groups, num_features),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(num_features, self.in_channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    def forward(self, x, t, c):\n",
    "        x = self.init(x)\n",
    "        down1 = self.down1(x)\n",
    "        down2 = self.down2(down1)\n",
    "        vector = self.to_vec(down2)\n",
    "        up0 = self.up0(vector)\n",
    "        # embeddings\n",
    "        # c = nn.functional.one_hot(c, num_classes=self.num_classes).type(tch.float)\n",
    "        c = nn.functional.one_hot(c.type(tch.int64), num_classes=self.num_classes).type(tch.float) \n",
    "\n",
    "        time1 = self.embedtime1(t).view(-1,2*self.num_features,1,1)\n",
    "        context1 = self.embedcontext1(c).view(-1,2*self.num_features,1,1)\n",
    "        # first skip connection\n",
    "        # first use of context and time as in the repo\n",
    "        # I don't use context guidance\n",
    "        up1 = self.up1(up0*context1+time1, down2)\n",
    "\n",
    "        #another embedding\n",
    "        time2 = self.embedtime2(t).view(-1,self.num_features,1,1)\n",
    "        context2 = self.embedcontext2(c).view(-1,self.num_features,1,1)   \n",
    "        up2 = self.up2(up1*context2+time2, down1)      \n",
    "\n",
    "        # another skip connection along channels   \n",
    "        out = self.out(tch.cat((up2,x), dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tch.randn(1,1,28,28)\n",
    "# t = tch.Tensor([1])\n",
    "# digit = tch.tensor([0])\n",
    "# print(a.shape)\n",
    "# model = ContextUnet(in_channels=1, num_features=64, num_classes=10)\n",
    "# model(a,t,digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 128\n",
    "num_classes = 10\n",
    "class diffusionModel(nn.Module):\n",
    "    def __init__(self,model = ContextUnet(1, num_features=num_features,num_classes=10)\n",
    "                 ,T=500, beta_1 = 10**-4, beta_T = 10**-2):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.T = T\n",
    "\n",
    "        betas = tch.linspace(beta_1, beta_T, T, device=device)  # Linear schedule from DDPM paper\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = tch.cumprod(alphas, dim=0)  # Cumulative product of alphas\n",
    "        diffusion_scheduler = alphas_cumprod\n",
    "        self.alphas = alphas\n",
    "        self.betas = betas\n",
    "        self.diffusion_scheduler= diffusion_scheduler\n",
    "        self.one_over_sqrt_alpha = 1/tch.sqrt(alphas)\n",
    "        self.one_minus_over_sqrt_alpha_bar = 1/tch.sqrt(1-diffusion_scheduler)\n",
    "        self.sqrt_beta = tch.sqrt(betas)\n",
    "    # for training the network. Just pass arguments through the network\n",
    "    def forward(self, x, t:tch.Tensor, c:tch.Tensor):\n",
    "        return self.model(x,t,c)\n",
    "    # for generating images\n",
    "    def generate_image(self, digit:int):\n",
    "        self.eval()\n",
    "        with tch.no_grad():\n",
    "            c = tch.tensor([digit]).to(device)\n",
    "            # generate x_T ~ N(0,1)\n",
    "            x_i = tch.randn(1,1,28,28).to(device)\n",
    "            for i in range(self.T, 0, -1):\n",
    "                t_current = tch.tensor([i/self.T]).to(device)\n",
    "                z = tch.randn(1,1,height,width) if i>1 else 0\n",
    "                eps = self(x_i,t_current,c)\n",
    "                x_i = (self.one_over_sqrt_alpha[i]*\n",
    "                       (x_i-\n",
    "              (1-self.alphas[i])/self.one_minus_over_sqrt_alpha_bar[i]*eps   )\n",
    "                   +self.sqrt_beta[i]*z\n",
    "                )\n",
    "\n",
    "        return x_i.detach().cpu().numpy()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modifiedUnet has 6,585,601 parameters.\n"
     ]
    }
   ],
   "source": [
    "diffModel = diffusionModel()\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "# optimizer and scheduler\n",
    "optimizer = tch.optim.AdamW(diffModel.parameters(), lr=1e-4,\n",
    "                            weight_decay=1e-5)\n",
    "# scheduler = tch.optim.lr_scheduler.StepLR(optim = diffusionModel()izer, step_size=10000,\n",
    "                                        #   gamma=0.2)\n",
    "loss_func = tch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in diffModel.parameters())\n",
    "\n",
    "print(f\"modifiedUnet has {total_params:,} parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def estimate_remaining_time(start_time, current_epoch, total_epochs):\n",
    "    \"\"\"Estimates the remaining training time.\n",
    "\n",
    "    Args:\n",
    "        start_time: The start time of the training process.\n",
    "        current_epoch: The current epoch number.\n",
    "        total_epochs: The total number of epochs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_per_epoch = elapsed_time / (current_epoch + 1)\n",
    "    remaining_time = time_per_epoch * (total_epochs - current_epoch - 1)\n",
    "    remaining_hours = int(remaining_time // 3600)\n",
    "    remaining_minutes = int((remaining_time % 3600) // 60)\n",
    "    remaining_seconds = int(remaining_time % 60)\n",
    "    print(f\"Estimated remaining time: {remaining_hours:02d}:{remaining_minutes:02d}:{remaining_seconds:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_203848/638539046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Divide timestep by overall time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# predicted_noise = diffModel(noised_image,labels, timesteps/diffModel.T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoised_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdiffModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_203848/4027051833.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t, c)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# for training the network. Just pass arguments through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# for generating images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_203848/3655587298.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t, c)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedtime1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mcontext1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedcontext1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# first skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_203848/3655587298.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "#training\n",
    "running_loss = 0.0\n",
    "epoch_loss_ = 0.0\n",
    "epoch_loss = 0.0\n",
    "n_epoch = 50\n",
    "\n",
    " \n",
    "for epoch in range(n_epoch):\n",
    "    i = 0\n",
    "    for data in train_loader:\n",
    "        ###### COMPLETER ICI ######\n",
    "        start_time = time.time()\n",
    "        loss_val = 0 \n",
    "        images,labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        timesteps = tch.randint(1, diffModel.T, size=(images.shape[0],), device=device)  # Move timesteps to the device\n",
    "        # generating a batch of random noise\n",
    "        \n",
    "        noise = tch.randn_like(images).to(device)\n",
    "        alpha_bar = diffusion_scheduler[timesteps].view(-1,1,1,1).to(device)\n",
    "        noised_image = (tch.sqrt(alpha_bar)*images\n",
    "                        +tch.sqrt(1-alpha_bar)*noise)\n",
    "        # Divide timestep by overall time\n",
    "        # predicted_noise = diffModel(noised_image,labels, timesteps/diffModel.T)\n",
    "        predicted_noise = diffModel(noised_image,labels, timesteps.type(tch.float32)/diffModel.T)\n",
    "\n",
    "        loss_val = loss_func(noise, predicted_noise)\n",
    "        ## Gradient calculation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        #####\n",
    "\n",
    "        running_loss += loss_val.item()\n",
    "        epoch_loss += loss_val.item()\n",
    "    print(f\"epoch= {epoch}\", end=\"\\r\", flush=True)\n",
    "    if epoch % 10 == 0:    # every 100 epoch...\n",
    "        disp_loss(epoch_loss, epoch)\n",
    "        estimate_remaining_time(start_time, epoch, n_epoch)\n",
    "\n",
    "    i = i+1\n",
    "    epoch_loss = 0.0\n",
    "    # scheduler.step()  \n",
    "print(\"Finished training\")\n",
    "#save the model weights after training\n",
    "tch.save(diffModel.state_dict(), 'model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading model from weights\n",
    "# state_dict = tch.load(\"model_weights.pth\")\n",
    "\n",
    "# # Load the state dictionary into the model\n",
    "# modifiedUnet.load_state_dict(state_dict)\n",
    "\n",
    "# modifiedUnet = modifiedUnet.to(device)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# modifiedUnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(images):\n",
    "    # for each image take a maximu of absolute values. Look at channels, height and width\n",
    "    # thus each image gets scaled individually\n",
    "    max_vals = tch.amax(tch.abs(images), dim=(1, 2, 3), keepdim=True)\n",
    "    # images are between [-1,1]\n",
    "    images = images/max_vals\n",
    "    return images\n",
    "# how to generate image from noise\n",
    "# algorith from DDPM paper\n",
    "def generate_image(n_images, labels, noise_predictor, device=device):\n",
    "    labels = tch.tensor(labels).to(device)\n",
    "    images = tch.randn(n_images, 1, height, width).to(device)\n",
    "    images = normalize_data(images)\n",
    "    i = T - 1  \n",
    "    while i >= 0:  \n",
    "        times = tch.tensor([i] * n_images).to(device)\n",
    "        alpha_bar = diffusion_scheduler[i].to(device)\n",
    "        if i > 0:  \n",
    "            noise = tch.randn(n_images, 1, height, width).to(device)\n",
    "        else:\n",
    "            noise = images * 0\n",
    "        images = (1 / tch.sqrt(alphas[i])) * (images - (1 - alphas[i]) / tch.sqrt(1 - diffusion_scheduler[i]) * noise_predictor(images, labels, times)) + tch.sqrt(betas[i]) * noise\n",
    "        images = normalize_data(images)\n",
    "        i = i - 1  # Decrement i for the next iteration\n",
    "    return images.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 850.394x141.732 with 6 Axes>,\n",
       " array([[<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>,\n",
       "         <AxesSubplot:>, <AxesSubplot:>]], dtype=object))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 850.394x141.732 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = generate_image(n_images=6, labels=[1,2,3,4,5,6], noise_predictor=modifiedUnet).squeeze(1)\n",
    "disp(images, shape = (1,6), scale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
